{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/evanupham/gpt-tiny-story?scriptVersionId=187567065\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom transformers import GPT2Tokenizer, get_linear_schedule_with_warmup\nimport numpy as np\n# Define the custom dataset class\nclass TinyStoriesDataset(Dataset):\n    def __init__(self, texts, tokenizer, max_length):\n        self.texts = [text for text in texts if text.strip() != '']  # Filter out empty sequences\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        tokens = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, truncation=True, padding='max_length')\n        input_ids = tokens.input_ids.squeeze(0)  # Ensure the correct dimension\n        attention_mask = tokens.attention_mask.squeeze(0)  # Ensure the correct dimension\n        return input_ids, attention_mask\n\n# Load the dataset\ndataset = load_dataset('roneneldan/TinyStories')\n\n# Initialize the GPT tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\n# Prepare the dataset\nmax_length = 1000\ntrain_texts = dataset['train']['text']\ntrain_dataset = TinyStoriesDataset(train_texts, tokenizer, max_length)\n\n# Create data loader\nbatch_size = 2\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\n# Define the GPT-2 model with dropout\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:x.size(0), :]\nclass GroupedQueryAttention(nn.Module):\n    def __init__(self, d_model, num_heads, num_groups=2, dropout=0.1):\n        super(GroupedQueryAttention, self).__init__()\n        self.num_heads = num_heads\n        self.num_groups = num_groups\n        self.d_model = d_model\n\n        assert d_model % (num_heads * num_groups) == 0\n\n        self.depth = d_model // (num_heads * num_groups)\n\n        self.wq = nn.Linear(d_model, d_model)\n        self.wk = nn.Linear(d_model, d_model)\n        self.wv = nn.Linear(d_model, d_model)\n\n        self.dense = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def split_heads(self, x, batch_size):\n        x = x.view(batch_size, -1, self.num_groups, self.num_heads, self.depth)\n        return x.permute(0, 2, 3, 1, 4)  # (batch_size, num_groups, num_heads, seq_len, depth)\n\n    def forward(self, q, k, v, mask):\n        batch_size = q.size(0)\n\n        q = self.split_heads(self.wq(q), batch_size)\n        k = self.split_heads(self.wk(k), batch_size)\n        v = self.split_heads(self.wv(v), batch_size)\n\n        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.depth)\n\n        if mask is not None:\n            mask = mask.unsqueeze(1).unsqueeze(1)  # (batch_size, 1, 1, seq_len, seq_len)\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n        attention_weights = self.dropout(attention_weights)\n        output = torch.matmul(attention_weights, v)\n\n        output = output.permute(0, 3, 1, 2, 4).contiguous().view(batch_size, -1, self.d_model)\n        output = self.dense(output)\n\n        return output, attention_weights\n\n    \nclass MoE(nn.Module):\n    def __init__(self, d_model, d_ff, n_experts=4, dropout=0.3, temperature=1.2):\n        super(MoE, self).__init__()\n        self.n_experts = n_experts\n        self.temperature = temperature\n        self.experts = nn.ModuleList([nn.Sequential(\n            nn.Linear(d_model, d_ff),\n            nn.SiLU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_ff, d_model),\n            nn.Dropout(dropout)\n        ) for _ in range(n_experts)])\n        \n        self.gating_network = nn.Linear(d_model, n_experts)\n        \n    def forward(self, x):\n        # Compute the gating weights\n        gate_logits = self.gating_network(x)\n        gate_outputs = F.gumbel_softmax(gate_logits, tau=self.temperature, hard=False)\n        \n        # Compute the expert outputs\n        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)\n        \n        # Combine expert outputs weighted by the gating network\n        output = torch.einsum('bld,blnd->bln', gate_outputs, expert_outputs)\n        \n        return output\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff, n_experts=5, dropout=0.3, temperature=0.8):\n        super(FeedForward, self).__init__()\n        self.moe_layer = MoE(d_model, d_ff, n_experts, dropout, temperature)\n        \n    def forward(self, x):\n        return self.moe_layer(x)\n\n\nclass GPTBlock(nn.Module):\n    def __init__(self, d_model, num_heads, num_groups, d_ff, dropout=0.3):\n        super(GPTBlock, self).__init__()\n        self.attention = GroupedQueryAttention(d_model, num_heads, num_groups, dropout)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.ffn = FeedForward(d_model, d_ff, n_experts=4, dropout=dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n\n    def forward(self, x, mask):\n        attn_output, _ = self.attention(x, x, x, mask)\n        out1 = self.norm1(x + attn_output)\n        ffn_output = self.ffn(out1)\n        out2 = self.norm2(out1 + ffn_output)\n        return out2\n\nclass GPT2(nn.Module):\n    def __init__(self, vocab_size, d_model, num_heads, num_groups, d_ff, num_layers, max_len=5000, dropout=0.3):\n        super(GPT2, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, d_model)\n        self.pos_encoding = PositionalEncoding(d_model, max_len)\n        self.layers = nn.ModuleList([GPTBlock(d_model, num_heads, num_groups, d_ff, dropout) for _ in range(num_layers)])\n        self.norm = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(d_model, vocab_size)\n\n    def forward(self, x, mask):\n        x = self.embedding(x)\n        x = self.pos_encoding(x)\n        for layer in self.layers:\n            x = layer(x, mask)\n        x = self.norm(x)\n        x = self.dropout(x)\n        return self.fc(x)\n\ndef create_future_mask(size):\n    mask = torch.tril(torch.ones(size, size)).unsqueeze(0)\n    return mask  # (1, size, size)\n\nvocab_size = len(tokenizer)\nd_model = 1536  # GPT-2 small model size\nnum_heads = 6\nd_ff = 3072\nnum_layers = 12\nmax_len = 1024\nnum_groups = 4\nmodel = GPT2(vocab_size, d_model, num_heads, num_groups, d_ff, num_layers, max_len)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nimport os\nmodel_path = \"/kaggle/working/model_weights_1536.pth\"\n# # Load the model weights if they exist\nif os.path.exists(model_path):\n    model.load_state_dict(torch.load(model_path))\n    print(f\"Model weights loaded from {model_path}\")\n\n# Training setup\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\n# Training loop with progress bar\nmodel.train()\n\n# Freeze all layers initially\nfor param in model.parameters():\n    param.requires_grad = False\n\ndef contains_repeated_ngram(seq, n):\n    ngrams = set()\n    for i in range(len(seq) - n + 1):\n        ngram = tuple(seq[i:i+n].tolist())\n        if ngram in ngrams:\n            return True\n        ngrams.add(ngram)\n    return False\n\ndef top_k_top_p_filtering(logits, top_k=0, top_p=1.0, min_p=0.0):\n    \"\"\"Filter a distribution of logits using top-k, top-p (nucleus), and min-p filtering\"\"\"\n    top_k = min(top_k, logits.size(-1))  # Safety check\n    if top_k > 0:\n        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n        logits[indices_to_remove] = -float('Inf')\n\n    if top_p < 1.0:\n        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n\n        sorted_indices_to_remove = cumulative_probs > top_p\n        if min_p > 0.0:\n            sorted_indices_to_remove &= (sorted_logits < min_p).cumsum(dim=-1).bool()\n\n        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n        sorted_indices_to_remove[..., 0] = 0\n\n        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n        logits[indices_to_remove] = -float('Inf')\n        \n    if min_p > 0.0:\n        logits[logits < min_p] = -float('Inf')\n\n    return logits\n\ndef apply_repetition_penalty(logits, seq, repetition_penalty):\n    \"\"\"Apply a penalty to the logits to discourage repetition\"\"\"\n    for token_id in seq:\n        logits[0, token_id] /= repetition_penalty\n    return logits\n\nimport torch\nimport torch.nn.functional as F\nfrom collections import defaultdict\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\ndef calculate_bleu(reference, hypothesis):\n    reference = [reference]  # BLEU expects a list of references\n    smoothie = SmoothingFunction().method4\n    return sentence_bleu(reference, hypothesis, smoothing_function=smoothie)\n\ndef contains_repeated_ngram(seq, n):\n    ngrams = set()\n    for i in range(len(seq) - n + 1):\n        ngram = tuple(seq[i:i+n].tolist())\n        if ngram in ngrams:\n            return True\n        ngrams.add(ngram)\n    return False\n\ndef top_k_top_p_filtering(logits, top_k=0, top_p=1.0, min_p=0.0):\n    \"\"\"Filter a distribution of logits using top-k, top-p (nucleus), and min-p filtering\"\"\"\n    top_k = min(top_k, logits.size(-1))  # Safety check\n    if top_k > 0:\n        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n        logits[indices_to_remove] = -float('Inf')\n\n    if top_p < 1.0:\n        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n\n        sorted_indices_to_remove = cumulative_probs > top_p\n        if min_p > 0.0:\n            sorted_indices_to_remove &= (sorted_logits < min_p).cumsum(dim=-1).bool()\n\n        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n        sorted_indices_to_remove[..., 0] = 0\n\n        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n        logits[indices_to_remove] = -float('Inf')\n        \n    if min_p > 0.0:\n        logits[logits < min_p] = -float('Inf')\n\n    return logits\n\ndef apply_repetition_penalty(logits, seq, repetition_penalty):\n    \"\"\"Apply a penalty to the logits to discourage repetition\"\"\"\n    for token_id in seq:\n        logits[0, token_id] /= repetition_penalty\n    return logits\n\ndef beam_search(model, tokenizer, input_text, beam_width=5, max_len=100, length_penalty=1.2, no_repeat_ngram_size=3, top_k=70, top_p=0.7, min_p=0.1, temperature=0.8, repetition_penalty=1.2, diversity_rate=0.3):\n    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n    input_ids = input_ids[:, :-1]  # Remove the last token for autoregressive generation\n\n    beam = [(input_ids, 0, [])]  # (input_ids, score, generated tokens)\n    completed_sequences = []\n    diversity_penalty = defaultdict(lambda: 0)\n\n    for step in range(max_len):\n        new_beam = []\n        for seq, score, generated_tokens in beam:\n            with torch.no_grad():\n                outputs = model(seq, create_future_mask(seq.size(1)).to(device))\n            logits = outputs[:, -1, :]  # Get the logits for the last token\n            logits = logits / temperature\n            logits = apply_repetition_penalty(logits, seq[0], repetition_penalty)\n            logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p, min_p=min_p)\n            probs = F.log_softmax(logits, dim=-1)\n            topk_probs, topk_ids = probs.topk(beam_width)\n\n            for i in range(beam_width):\n                next_seq = torch.cat([seq, topk_ids[:, i:i+1]], dim=-1)\n                new_score = score + topk_probs[0, i].item()\n                new_generated_tokens = generated_tokens + [topk_ids[0, i].item()]\n\n                if no_repeat_ngram_size > 0 and contains_repeated_ngram(next_seq[0], no_repeat_ngram_size):\n                    continue  # Skip sequences with repeated n-grams\n\n                # Diversity penalty\n                diversity_penalty[tuple(map(tuple, next_seq.tolist()))] += diversity_rate * step\n                new_score -= diversity_penalty[tuple(map(tuple, next_seq.tolist()))]\n\n                new_beam.append((next_seq, new_score, new_generated_tokens))\n\n        if not new_beam:\n            break  # Break the loop if no new sequences are generated\n\n        beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_width]\n\n        # Check for completed sequences (sequences that have the end token)\n        for seq, score, generated_tokens in beam:\n            if seq[0, -1] == tokenizer.eos_token_id:\n                length_normalized_score = score / (seq.size(1) ** length_penalty)\n                completed_sequences.append((seq, length_normalized_score, generated_tokens))\n\n        # Keep only the sequences that are not completed\n        beam = [b for b in beam if b[0][0, -1] != tokenizer.eos_token_id]\n\n        # Early stopping if all sequences are completed\n        if not beam:\n            break\n\n    if completed_sequences:\n        best_seq = sorted(completed_sequences, key=lambda x: x[1], reverse=True)[0]\n    else:\n        if beam:\n            best_seq = beam[0]  # Fallback to the best beam\n        else:\n            return \"\"  # Return an empty string if no valid sequence is found\n\n    best_seq_tokens = best_seq[2]\n    reference = tokenizer.encode(input_text)  # Use the input text as the reference\n    bleu_score = calculate_bleu(reference, best_seq_tokens)\n\n    output_text = tokenizer.decode(best_seq[0].squeeze(), skip_special_tokens=True)\n    return output_text, bleu_score\n\ndef set_requires_grad(model, layer_idx, requires_grad):\n    for i, layer in enumerate(model.layers):\n        for param in layer.parameters():\n            param.requires_grad = (i == layer_idx) and requires_grad\n\ndef get_custom_training_sequence(num_layers):\n        return [1, 2, 1, 3, 2, 4, 3, 5, 4, 6, 5, 7, 6, 8, 7, 9, 8, 10, 9, 11, 10, 12, 11, 12]\n\nnum_layers = len(model.layers)\ntraining_sequence = get_custom_training_sequence(num_layers)\n\nnum_epochs = len(training_sequence)\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=total_steps // 10, num_training_steps=total_steps)\ncriterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\ndataset_size = 1000  # Number of samples per epoch\n\ndef parabolic_scaling(epoch, num_epochs):\n    mid_epoch = num_epochs // 2\n    return -4 * ((epoch - mid_epoch) ** 2) / (num_epochs ** 2) + 1\nimport textstat\n\ndef parabolic_scale_readability_score(text, target_grade, grade_range):\n    # Calculate the Flesch-Kincaid Grade Level\n    fk_grade = textstat.flesch_kincaid_grade(text)\n    \n    # Parabolic scaling\n    scaled_score = 1 - ((fk_grade - target_grade) / grade_range) ** 2\n    \n    # Clip the scaled score to be within the range [-1, 1]\n    scaled_score = max(min(scaled_score, 1), -1)\n    \n    return scaled_score\nfrom rouge_score import rouge_scorer\n\n# Define the ROUGE score calculation function\ndef calculate_rouge(reference, hypothesis, tokenizer):\n    reference_text = tokenizer.decode(reference, skip_special_tokens=True)\n    hypothesis_text = tokenizer.decode(hypothesis, skip_special_tokens=True)\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = scorer.score(reference_text, hypothesis_text)\n    return scores\n\n# Define the BLEU score calculation function\ndef calculate_bleu(reference, hypothesis):\n    reference = [reference]  # BLEU expects a list of references\n    smoothie = SmoothingFunction().method4\n    return sentence_bleu(reference, hypothesis, smoothing_function=smoothie)\n\ndef z_loss(logits, beta=1e-4):\n    \"\"\"Z-Loss regularizes logits to prevent extreme values.\"\"\"\n    log_z = torch.logsumexp(logits, dim=-1)\n    return beta * log_z.pow(2).mean()\nstart_epoch = 0\nfor epoch in range(start_epoch, num_epochs):\n    # Determine which layer to unfreeze according to the training sequence\n    layer_to_unfreeze = training_sequence[epoch] - 1\n    set_requires_grad(model, layer_to_unfreeze, True)\n    \n    # Create a new subset of the dataset\n    indices = np.random.choice(len(train_dataset), dataset_size, replace=False)\n    subset = Subset(train_dataset, indices)\n    train_loader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n        \n    total_loss = 0\n    total_bleu_score = 0\n    total_rouge_score = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", postfix={\"Loss\": 0.0000, \"Perplexity\": 0.0000, \"BLEU\": 0.0000})\n    \n    for batch in progress_bar:\n        input_ids, attention_mask = batch\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        # Shift the input for the next token prediction\n        labels = input_ids[:, 1:].contiguous()\n        input_ids = input_ids[:, :-1].contiguous()\n        \n        # Create future mask\n        seq_length = input_ids.size(1)\n        mask = create_future_mask(seq_length).to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids, mask)\n        \n        # Compute loss\n        loss = criterion(outputs.view(-1, vocab_size), labels.view(-1))\n        \n        # Generate sequences for reward calculation\n        generated_ids = outputs.argmax(dim=-1).cpu().numpy()\n        references = labels.cpu().numpy()\n        batch_bleu_score = 0\n        batch_rouge_score = 0\n        rewards = []\n        for ref, gen in zip(references, generated_ids):\n            ref_tokens = ref.tolist()\n            gen_tokens = gen.tolist()\n            bleu_score = calculate_bleu(ref_tokens, gen_tokens)\n            rouge_score = calculate_rouge(ref_tokens, gen_tokens, tokenizer)\n            rouge_l_score = rouge_score['rougeL'].fmeasure  # Using ROUGE-L F1-score as the reward\n            rewards.append(rouge_l_score)\n            batch_bleu_score += bleu_score\n            batch_rouge_score += rouge_l_score\n        \n        avg_bleu_score = batch_bleu_score / len(references)\n        avg_rouge_score = batch_rouge_score / len(references)\n        \n        # REINFORCE algorithm\n        rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n        log_probs = F.log_softmax(outputs, dim=-1)\n        log_probs = log_probs.gather(2, labels.unsqueeze(-1)).squeeze(-1)\n        policy_loss = -log_probs * rewards.unsqueeze(-1)\n        policy_loss = policy_loss.mean() * parabolic_scaling(epoch, num_epochs)\n        zloss_value = z_loss(outputs)\n        total_loss_with_reward = loss + zloss_value + policy_loss\n        total_loss_with_reward.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += total_loss_with_reward.item()\n        total_bleu_score += avg_bleu_score\n        total_rouge_score += avg_rouge_score\n        avg_loss = total_loss / len(progress_bar)\n        perplexity = torch.exp(torch.tensor(loss)).item()\n        progress_bar.set_postfix(Loss=f\"{loss.item():.4f}\", Perplexity=f\"{perplexity:.4f}\", BLEU=f\"{avg_bleu_score:.4f}\", ROUGE=f\"{avg_rouge_score:.4f}\")\n    \n    avg_loss = total_loss / len(train_loader)\n    perplexity = torch.exp(torch.tensor(avg_loss)).item()\n    avg_bleu_score = total_bleu_score / len(train_loader)\n    avg_rouge_score = total_rouge_score / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss_with_reward.item():.4f}, Perplexity: {perplexity:.4f}, Avg BLEU: {avg_bleu_score:.4f}, Avg ROUGE: {avg_rouge_score:.4f}\")\n    generated_text, bleu_score = beam_search(model, tokenizer, \"Once upon a time\", beam_width=5, max_len=50)\n    print(f\"Generated text: {generated_text}\")\n    print(f\"BLEU score: {bleu_score:.4f}\")  \n    # Save model weights\n    torch.save(model.state_dict(), model_path)\n    print(f\"Model weights saved to {model_path}\")\n    \n    # Freeze the previously unfrozen layer\n    set_requires_grad(model, layer_to_unfreeze, False)\n\nprint(\"Training complete.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T17:50:11.412854Z","iopub.execute_input":"2024-07-08T17:50:11.413244Z","iopub.status.idle":"2024-07-08T21:17:04.628108Z","shell.execute_reply.started":"2024-07-08T17:50:11.413213Z","shell.execute_reply":"2024-07-08T21:17:04.627069Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"},{"name":"stdout","text":"Model weights loaded from /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/24:   0%|          | 0/500 [00:00<?, ?it/s, BLEU=0, Loss=0, Perplexity=0]2024-07-08 17:50:35.209892: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 17:50:35.209953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 17:50:35.211682: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/tmp/ipykernel_1291/1298449446.py:491: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  perplexity = torch.exp(torch.tensor(loss)).item()\nEpoch 1/24: 100%|██████████| 500/500 [10:13<00:00,  1.23s/it, BLEU=0.5198, Loss=7.7639, Perplexity=2354.0771, ROUGE=0.1572]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/24, Loss: 7.7823, Perplexity: 1957.1715, Avg BLEU: 0.7994, Avg ROUGE: 0.2291\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so the park and said, \".\n\n\n\" and he was so her to the little girl, \" and said. The to her mom was a big\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/24: 100%|██████████| 500/500 [09:49<00:00,  1.18s/it, BLEU=0.8439, Loss=7.7248, Perplexity=2263.6941, ROUGE=0.2355]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/24, Loss: 7.7969, Perplexity: 2052.9524, Avg BLEU: 0.7953, Avg ROUGE: 0.2289\nGenerated text: Once upon a time, there was a little girl. She was very to the little and the park. He was so her to the park, \" and said, he was very.\n\n\". She said, but it was a big and said. The\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/24: 100%|██████████| 500/500 [10:07<00:00,  1.22s/it, BLEU=0.8187, Loss=7.4183, Perplexity=1666.2378, ROUGE=0.2162]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/24, Loss: 7.5413, Perplexity: 2108.8716, Avg BLEU: 0.8036, Avg ROUGE: 0.2311\nGenerated text: Once upon a time, there was a little girl. He was so to the park. She was very to the little and said, \" day, \".\n\nThe the park, but her and he was a big and said. She had a big to\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/24: 100%|██████████| 500/500 [09:28<00:00,  1.14s/it, BLEU=0.8264, Loss=7.2186, Perplexity=1364.5940, ROUGE=0.2000]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/24, Loss: 7.3619, Perplexity: 2282.2429, Avg BLEU: 0.8008, Avg ROUGE: 0.2248\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so the park and said, \" to her mom and he was so to the little.\n\n\", but she was a big. She said, but it\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/24: 100%|██████████| 500/500 [09:48<00:00,  1.18s/it, BLEU=0.7541, Loss=7.8442, Perplexity=2550.8879, ROUGE=0.1994]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/24, Loss: 8.0695, Perplexity: 2347.3743, Avg BLEU: 0.7972, Avg ROUGE: 0.2244\nGenerated text: Once upon a time, there was a little. She was very to the\n\nThe. He was so the park. She said, \" and said, but she was so to the park and he was a big. The to the little girl, \" her\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/24: 100%|██████████| 500/500 [09:09<00:00,  1.10s/it, BLEU=0.8420, Loss=7.3535, Perplexity=1561.6176, ROUGE=0.2494]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/24, Loss: 7.5960, Perplexity: 2411.4050, Avg BLEU: 0.7983, Avg ROUGE: 0.2243\nGenerated text: Once upon a time, there was a little girl. She was very to the park.\n\nThe, \" the park and said, but it was so he was a big and said. He was so her to the little. She said, \" and the\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/24: 100%|██████████| 500/500 [09:28<00:00,  1.14s/it, BLEU=0.7075, Loss=7.1329, Perplexity=1252.5162, ROUGE=0.2636]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/24, Loss: 7.5618, Perplexity: 2527.5212, Avg BLEU: 0.8006, Avg ROUGE: 0.2256\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so the park and said, \" her.\n\n\nThe was a big to the little. He said, but he was so her to the\" and said\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/24: 100%|██████████| 500/500 [08:48<00:00,  1.06s/it, BLEU=0.7615, Loss=7.9554, Perplexity=2851.0002, ROUGE=0.2286]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/24, Loss: 8.3601, Perplexity: 2536.5933, Avg BLEU: 0.8035, Avg ROUGE: 0.2283\nGenerated text: Once upon a time, there was a little girl. He was so to the park. She was very to the\n\nThe and said, \" the big and said. They day, but he was so her mom. The to play with the park and it\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/24: 100%|██████████| 500/500 [09:09<00:00,  1.10s/it, BLEU=0.6268, Loss=7.5740, Perplexity=1946.9353, ROUGE=0.2340]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/24, Loss: 8.1117, Perplexity: 2594.6650, Avg BLEU: 0.7984, Avg ROUGE: 0.2270\nGenerated text: Once upon a time, there was a little girl. She was very her to the park. He was so the park and said, \" to the\n\n\nThe. She had a big, \" and he was so to play, but it. The and\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/24: 100%|██████████| 500/500 [08:30<00:00,  1.02s/it, BLEU=0.8465, Loss=7.3757, Perplexity=1596.6635, ROUGE=0.2321]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/24, Loss: 7.6725, Perplexity: 2641.0681, Avg BLEU: 0.7985, Avg ROUGE: 0.2276\nGenerated text: Once upon a time, there was a little. He was so was very to the park.\n\nThe and said, \". She was so the park to the big, but the day, \" her and he was a big and said. She said,\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/24: 100%|██████████| 500/500 [08:50<00:00,  1.06s/it, BLEU=0.6905, Loss=7.3480, Perplexity=1553.0466, ROUGE=0.2494]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/24, Loss: 7.8930, Perplexity: 2714.9321, Avg BLEU: 0.7961, Avg ROUGE: 0.2254\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so her to the\nThe and said, \", but he was a big and said.\n\n\". The to the little girl, \" day, \"\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/24: 100%|██████████| 500/500 [08:10<00:00,  1.02it/s, BLEU=0.7672, Loss=7.4378, Perplexity=1698.9619, ROUGE=0.1852]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/24, Loss: 7.8170, Perplexity: 2720.5591, Avg BLEU: 0.7993, Avg ROUGE: 0.2284\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so a big, \" and said, but the.\n\nThe to the little girl and he was so the park and said. She had a big to her\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/24: 100%|██████████| 500/500 [08:29<00:00,  1.02s/it, BLEU=0.8648, Loss=7.5344, Perplexity=1871.3489, ROUGE=0.2293]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/24, Loss: 7.8324, Perplexity: 2732.2610, Avg BLEU: 0.8002, Avg ROUGE: 0.2288\nGenerated text: Once upon a time, there was a little girl. She was so to the park. He was very to the little and said, \".\n\nThe was so her and he had a big, but the park, \" it. He said, she and\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/24: 100%|██████████| 500/500 [07:50<00:00,  1.06it/s, BLEU=0.7907, Loss=7.3777, Perplexity=1599.9222, ROUGE=0.2264]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/24, Loss: 7.7449, Perplexity: 2658.0115, Avg BLEU: 0.7978, Avg ROUGE: 0.2297\nGenerated text: Once upon a time, there was a little girl. She was so he was very to the park. He was a big and said, \".\n\nThe and the park, but her to her to the little. She said, but it was so the\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/24: 100%|██████████| 500/500 [08:10<00:00,  1.02it/s, BLEU=0.7474, Loss=7.3866, Perplexity=1614.2255, ROUGE=0.2374]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/24, Loss: 7.8598, Perplexity: 2688.3726, Avg BLEU: 0.7988, Avg ROUGE: 0.2313\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so the park and said, \" and he was so she was a big to the\n\n\". She said, but her. They had to play and the\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/24: 100%|██████████| 500/500 [07:31<00:00,  1.11it/s, BLEU=0.8096, Loss=8.1361, Perplexity=3415.7236, ROUGE=0.2008]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/24, Loss: 8.4751, Perplexity: 2616.9038, Avg BLEU: 0.7983, Avg ROUGE: 0.2287\nGenerated text: Once upon a time, there was a little girl. She was so to the park. He was very and said, \" day, he was very to the big.\n\n\" and the park, \" her and said. They had a big to her mom\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/24: 100%|██████████| 500/500 [07:50<00:00,  1.06it/s, BLEU=0.8004, Loss=7.7077, Perplexity=2225.3813, ROUGE=0.2315]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/24, Loss: 8.0796, Perplexity: 2594.4214, Avg BLEU: 0.7990, Avg ROUGE: 0.2287\nGenerated text: Once upon a time, there was a little. She was very to the park. He was so the\nThe and said, \" day, but the park and he was a big to play.\n\" and said. They her to the little girl, \"\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/24: 100%|██████████| 500/500 [07:10<00:00,  1.16it/s, BLEU=0.8300, Loss=7.5270, Perplexity=1857.4589, ROUGE=0.2849]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/24, Loss: 7.8898, Perplexity: 2461.3306, Avg BLEU: 0.8022, Avg ROUGE: 0.2322\nGenerated text: Once upon a time, there was a little. He was very to the park. She was so he was very a big and said, \" to the little girl.\n\n\nThe \n\". She said, but the park and she was so her\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/24: 100%|██████████| 500/500 [07:29<00:00,  1.11it/s, BLEU=0.8977, Loss=7.2638, Perplexity=1427.6962, ROUGE=0.2492]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/24, Loss: 7.4451, Perplexity: 2391.1748, Avg BLEU: 0.8074, Avg ROUGE: 0.2323\nGenerated text: Once upon a time, there was a little girl. She was so to the park. He was very to the\n\nThe and said, \" day, but he was a big. The and said. She had to her mom and the park, \" her\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/24: 100%|██████████| 500/500 [06:52<00:00,  1.21it/s, BLEU=0.8082, Loss=7.5846, Perplexity=1967.6162, ROUGE=0.2029]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/24, Loss: 7.8214, Perplexity: 2367.7271, Avg BLEU: 0.7945, Avg ROUGE: 0.2308\nGenerated text: Once upon a time, there was a little. He was so to the park.\n\nThe. She was so the park and said, \" day, \" and he was very to the little girl and said. She had a big, but he was so\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/24: 100%|██████████| 500/500 [07:13<00:00,  1.15it/s, BLEU=0.8705, Loss=7.1803, Perplexity=1313.3145, ROUGE=0.2731]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/24, Loss: 7.3675, Perplexity: 2240.8469, Avg BLEU: 0.7924, Avg ROUGE: 0.2291\nGenerated text: Once upon a time, there was a little girl.\nThe, \" was so to the park. She was very to her and said, but the little girl and said. He was a big to play. She had a big and he was so the park\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/24: 100%|██████████| 500/500 [06:31<00:00,  1.28it/s, BLEU=0.7563, Loss=7.4825, Perplexity=1776.6440, ROUGE=0.2330]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/24, Loss: 7.7124, Perplexity: 2083.7578, Avg BLEU: 0.8002, Avg ROUGE: 0.2337\nGenerated text: Once upon a time, there was a little girl. He was very to the park. She was so he was a big to play and said, \".\nThe day, but the park and he was so her mom and said. She had a big and\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/24: 100%|██████████| 500/500 [06:51<00:00,  1.21it/s, BLEU=0.8355, Loss=7.4757, Perplexity=1764.6826, ROUGE=0.2295]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/24, Loss: 7.5937, Perplexity: 1992.4585, Avg BLEU: 0.8024, Avg ROUGE: 0.2349\nGenerated text: Once upon a time, there was a little girl. She was very to the park. He was so the park and said, \" her.\n\n\", but he was a big and said. She had a big to play with the little girl, \"\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/24: 100%|██████████| 500/500 [06:32<00:00,  1.28it/s, BLEU=0.8283, Loss=7.1977, Perplexity=1336.3148, ROUGE=0.2311]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/24, Loss: 7.2683, Perplexity: 1877.3755, Avg BLEU: 0.7973, Avg ROUGE: 0.2332\nGenerated text: Once upon a time, there was a little girl. She was so to the park.\n\nThe, \" said, but the park and said. He was so he was very to the little girl and saw a big and said, \" her to play.\nBLEU score: 0.1881\nModel weights saved to /kaggle/working/model_weights_1536.pth\nTraining complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rouge-score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install textstat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\n\ndef get_custom_training_sequence(num_layers, mode='forwards'):\n    if mode == 'forwards':\n        return [1, 2, 1, 3, 2, 4, 3, 5, 4, 6, 5, 7, 6, 8, 7, 9, 8, 10, 9, 11, 10, 12, 11, 12]\n\n    elif mode == 'backwards':\n        return [12, 11, 12, 10, 11, 9, 10, 8, 9, 7, 8, 6, 7, 5, 6, 4, 5, 3, 4, 2, 3, 1, 2, 1]\n\n    elif mode == 'random':\n        layers = list(range(1, num_layers + 1))\n        sequence = layers + layers\n        random.shuffle(sequence)\n        return sequence\n\n    else:\n        raise ValueError(\"Mode must be one of 'forwards', 'backwards', or 'random'.\")\n\n# Example usage:\nnum_layers = 12\nforwards_sequence = get_custom_training_sequence(num_layers, mode='forwards')\nbackwards_sequence = get_custom_training_sequence(num_layers, mode='backwards')\nrandom_sequence = get_custom_training_sequence(num_layers, mode='random')\n\nforwards_sequence, backwards_sequence, random_sequence\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"model_weights.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(f\"Model weights saved to {model_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom collections import defaultdict\n\ndef create_future_mask(size):\n    mask = torch.tril(torch.ones(size, size)).unsqueeze(0).unsqueeze(0)\n    return mask  # (1, 1, size, size)\n\n\nimport torch\nimport torch.nn.functional as F\nfrom collections import defaultdict\nimport nltk\nclass GroupedQueryAttention(nn.Module):\n    def __init__(self, d_model, num_heads, num_groups=2, dropout=0.1):\n        super(GroupedQueryAttention, self).__init__()\n        self.num_heads = num_heads\n        self.num_groups = num_groups\n        self.d_model = d_model\n\n        assert d_model % (num_heads * num_groups) == 0\n\n        self.depth = d_model // (num_heads * num_groups)\n\n        self.wq = nn.Linear(d_model, d_model)\n        self.wk = nn.Linear(d_model, d_model)\n        self.wv = nn.Linear(d_model, d_model)\n\n        self.dense = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def split_heads(self, x, batch_size):\n        x = x.view(batch_size, -1, self.num_groups, self.num_heads, self.depth)\n        return x.permute(0, 2, 3, 1, 4)  # (batch_size, num_groups, num_heads, seq_len, depth)\n\n    def forward(self, q, k, v, mask):\n        batch_size = q.size(0)\n\n        q = self.split_heads(self.wq(q), batch_size)\n        k = self.split_heads(self.wk(k), batch_size)\n        v = self.split_heads(self.wv(v), batch_size)\n\n        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.depth)\n\n        if mask is not None:\n            mask = mask.unsqueeze(1).unsqueeze(2).unsqueeze(3)  # (batch_size, 1, 1, 1, seq_len)\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        attention_weights = torch.nn.functional.softmax(scores, dim=-1)\n        attention_weights = self.dropout(attention_weights)\n        output = torch.matmul(attention_weights, v)\n\n        output = output.permute(0, 3, 1, 2, 4).contiguous().view(batch_size, -1, self.d_model)\n        output = self.dense(output)\n\n        return output, attention_weights\n\ndef calculate_bleu(reference, hypothesis):\n    reference = [reference]  # BLEU expects a list of references\n    smoothie = SmoothingFunction().method4\n    return sentence_bleu(reference, hypothesis, smoothing_function=smoothie)\n\ndef contains_repeated_ngram(seq, n):\n    ngrams = set()\n    for i in range(len(seq) - n + 1):\n        ngram = tuple(seq[i:i+n].tolist())\n        if ngram in ngrams:\n            return True\n        ngrams.add(ngram)\n    return False\n\ndef top_k_top_p_filtering(logits, top_k=0, top_p=1.0, min_p=0.0):\n    \"\"\"Filter a distribution of logits using top-k, top-p (nucleus), and min-p filtering\"\"\"\n    top_k = min(top_k, logits.size(-1))  # Safety check\n    if top_k > 0:\n        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n        logits[indices_to_remove] = -float('Inf')\n\n    if top_p < 1.0:\n        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n\n        sorted_indices_to_remove = cumulative_probs > top_p\n        if min_p > 0.0:\n            sorted_indices_to_remove &= (sorted_logits < min_p).cumsum(dim=-1).bool()\n\n        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n        sorted_indices_to_remove[..., 0] = 0\n\n        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n        logits[indices_to_remove] = -float('Inf')\n        \n    if min_p > 0.0:\n        logits[logits < min_p] = -float('Inf')\n\n    return logits\n\ndef apply_repetition_penalty(logits, seq, repetition_penalty):\n    \"\"\"Apply a penalty to the logits to discourage repetition\"\"\"\n    for token_id in seq:\n        logits[0, token_id] /= repetition_penalty\n    return logits\n\ndef beam_search(model, tokenizer, input_text, beam_width=5, max_len=100, length_penalty=1.2, no_repeat_ngram_size=3, top_k=70, top_p=0.7, min_p=0.1, temperature=0.8, repetition_penalty=1.2, diversity_rate=0.3):\n    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n    input_ids = input_ids[:, :-1]  # Remove the last token for autoregressive generation\n\n    beam = [(input_ids, 0, [])]  # (input_ids, score, generated tokens)\n    completed_sequences = []\n    diversity_penalty = defaultdict(lambda: 0)\n\n    for step in range(max_len):\n        new_beam = []\n        for seq, score, generated_tokens in beam:\n            with torch.no_grad():\n                outputs, _ = model(seq, create_future_mask(seq.size(1)).to(device))\n            logits = outputs[:, -1, :]  # Get the logits for the last token\n            logits = logits / temperature\n            logits = apply_repetition_penalty(logits, seq[0], repetition_penalty)\n            logits = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p, min_p=min_p)\n            probs = F.log_softmax(logits, dim=-1)\n            topk_probs, topk_ids = probs.topk(beam_width)\n\n            for i in range(beam_width):\n                next_seq = torch.cat([seq, topk_ids[:, i:i+1]], dim=-1)\n                new_score = score + topk_probs[0, i].item()\n                new_generated_tokens = generated_tokens + [topk_ids[0, i].item()]\n\n                if no_repeat_ngram_size > 0 and contains_repeated_ngram(next_seq[0], no_repeat_ngram_size):\n                    continue  # Skip sequences with repeated n-grams\n\n                # Diversity penalty\n                diversity_penalty[tuple(map(tuple, next_seq.tolist()))] += diversity_rate * step\n                new_score -= diversity_penalty[tuple(map(tuple, next_seq.tolist()))]\n\n                new_beam.append((next_seq, new_score, new_generated_tokens))\n\n        if not new_beam:\n            break  # Break the loop if no new sequences are generated\n\n        beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_width]\n\n        # Check for completed sequences (sequences that have the end token)\n        for seq, score, generated_tokens in beam:\n            if seq[0, -1] == tokenizer.eos_token_id:\n                length_normalized_score = score / (seq.size(1) ** length_penalty)\n                completed_sequences.append((seq, length_normalized_score, generated_tokens))\n\n        # Keep only the sequences that are not completed\n        beam = [b for b in beam if b[0][0, -1] != tokenizer.eos_token_id]\n\n        # Early stopping if all sequences are completed\n        if not beam:\n            break\n\n    if completed_sequences:\n        best_seq = sorted(completed_sequences, key=lambda x: x[1], reverse=True)[0]\n    else:\n        if beam:\n            best_seq = beam[0]  # Fallback to the best beam\n        else:\n            return \"\"  # Return an empty string if no valid sequence is found\n\n    best_seq_tokens = best_seq[2]\n    reference = tokenizer.encode(input_text)  # Use the input text as the reference\n    bleu_score = calculate_bleu(reference, best_seq_tokens)\n\n    output_text = tokenizer.decode(best_seq[0].squeeze(), skip_special_tokens=True)\n    return output_text, bleu_score\n\n\n\n\n\ngenerated_text, bleu_score = beam_search(model, tokenizer, \"Once upon a time\", beam_width=5, max_len=50)\nprint(f\"Generated text: {generated_text}\")\nprint(f\"BLEU score: {bleu_score:.4f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}